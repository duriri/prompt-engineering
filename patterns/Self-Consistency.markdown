# ğŸ§  Self-Consistency Prompting

Self-Consistency Prompting is an advanced technique used in prompt engineering to enhance the **accuracy** and **reliability** of outputs from Large Language Models (LLMs). Instead of relying on a single reasoning path, this method generates multiple reasoning chains and selects the final answer through **majority voting**.

---

## âœ¨ Why Use Self-Consistency?

While LLMs can follow reasoning chains (using Chain-of-Thought prompting), their outputs may still vary due to randomness or slight missteps in logic. By using Self-Consistency, we mitigate this problem:

* âœ… More stable outputs
* âœ… Fewer reasoning errors
* âœ… Higher accuracy, especially on complex problems

---

## ğŸ› ï¸ How It Works

1. Prompt the model using **Chain of Thought (CoT)** prompting
2. Sample **multiple outputs** (e.g., 5â€“10 generations) using a non-zero temperature (e.g., `temperature=0.7`)
3. Extract the **final answer** from each chain
4. Return the answer that appears **most frequently** (majority vote)

---

## ğŸ“¦ Example

### ğŸ”¹ Prompt:

```text
Solve the following problem step-by-step:
If you buy 3 books that cost $12 each and get a $6 discount, how much do you pay?

Let's think step by step.
```

### ğŸ”¹ Sampled Outputs:

1. 3 Ã— 12 = 36 â†’ 36 âˆ’ 6 = **30**
2. 12 Ã— 3 = 36 â†’ 36 âˆ’ 6 = **30**
3. 3 books: 3 Ã— 12 = 36 â†’ total cost = 36 âˆ’ 6 = **30**
4. 3 Ã— 12 = 36 â†’ discount is 6 â†’ 36 âˆ’ 6 = **30**
5. 12 âˆ’ 6 = 6 â†’ 6 Ã— 3 = **18** âŒ (incorrect logic)

### âœ… Final Answer (by majority):

**30**

---

## âœ… Best Practices

* Use **Chain-of-Thought** style prompts that guide the model through reasoning
* Generate **5 to 10 completions** for each prompt
* Use a **moderate temperature** (e.g., 0.7) to encourage variation in reasoning paths
* Use a **voting mechanism** to select the final answer

---

## ğŸ§ª When to Use

Self-Consistency is particularly effective for:

* ğŸ§¶ Math word problems
* ğŸ¤© Logical puzzles
* ğŸ”— Multi-step reasoning tasks
* ğŸ§  Symbol manipulation or programming-related generation

---

## ğŸ“š Reference

Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., ... & Le, Q. (2022). **Chain of Thought Prompting Elicits Reasoning in Large Language Models**. *arXiv preprint arXiv:2201.11903*.
